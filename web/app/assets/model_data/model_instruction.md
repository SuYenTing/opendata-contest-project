## 模型建構說明

---

### 一、摘要

我們主要以極限梯度提升模型(eXtreme Gradient Boosting; 以下簡稱XGBoost)，來預測台灣的已婚女性是否有小孩(兩分類的問題)。透過建立機器學習模型，我們可以SHAP(SHapley Additive exPlanations)來觀察模型是怎麼去做預測。接下將依序分別說明樣本建構流程、特徵資料說明及預測模型建構方法。

---

### 二、樣本建構流程

#### 1. 資料篩選

本次資料基底為內政大數據模擬資料集的108年人+建物+地理資訊模擬資料，共計有2,359,385筆資料。

由於我們分析的目標為已婚女性不生小孩的原因，故我們針對樣本先進行篩選，篩選條件分別為：

| 條件 | 篩選後樣本數 |
| -------- | -------- |
| 未篩選 | 2,359,385 |
| 女性 | 1,153,821 |
| 適育年齡(20-40歲) | 366,237 |
| 已婚 | 132,747 |
| 刪除缺值 | 110,888 |

* 刪除缺值: 若樣本在教育程度、出生子女數及有殼分類欄位中有任一缺值，則刪除該樣本

    

#### 2. 模型預測目標

模型主要為預測兩分類，我們以資料的出生子女數欄位為依據：若出生子女數等於0為「沒小孩」的分類; 若出生子女數大於0則為「有小孩」的分類。

| 類別 | 樣本數 | 佔比 |
| -------- | -------- | -------- |
| 有小孩 | 24,578 | 22.16% |
| 沒小孩 | 86,310 | 77.84% |
| 全部 | 110,888 | 100% | 

    

#### 3. 訓練集/測試集切割

為能夠檢驗模型的預測能力，我們針對篩選後的110,888筆樣本採分層抽樣，依相同預測分類且為相同里的樣本組，隨機切分80/20做為訓練集及測試集。經分層抽樣隨機切分樣本後，訓練集與測試集在各分類的樣本數為：

| 資料類別 | 分類 | 樣本數 | 比率 |
| -------- | -------- | -------- | -------- |
| 訓練集 | 有小孩 | 62,001 | 77.61% |
|  | 沒小孩 | 17,891 | 22.39% |
|  | 總計 | 79,892 | 100% |
| 測試集 | 有小孩 | 18,220  | 78.81% |
|  | 沒小孩 | 4,900 | 21.19% | 
|  | 總計 | 23,120 | 100% |

    

---

### 三、特徵資料說明

為能夠加強模型的預測能力，除使用內政部提供的人+建物+地理資訊模擬資料外，我們另外尋找其他相關特徵指標放入模型內。

下表為模型內使用到的特徵及其資料來源：

| 編號 | 特徵名稱 | 資料來源 | 資料層級 | 提供單位 | 備註 |
| --- | --- | --- | --- | --- | --- | --- |
|1|年紀|人+建物+地理資訊模擬資料|個人|內政部||
|2|教育程度|人+建物+地理資訊模擬資料|個人|內政部||
|3|是否為原住民身分|人+建物+地理資訊模擬資料|個人|內政部||
|4|是否為身心障礙|人+建物+地理資訊模擬資料|個人|內政部||
|5|是否為中低收入戶|人+建物+地理資訊模擬資料|個人|內政部||
|6|是否有殼|人+建物+地理資訊模擬資料|個人|內政部||
|7|人口密度|SEGIS行政區資料|里|內政部||
|8|老化指數|SEGIS行政區資料|里|內政部||
|9|社會增加率|SEGIS行政區資料|里|內政部||
|10|房價所得比|內政部不動產資訊平台|縣市|內政部||
|11|失業率|內政部不動產資訊平台|縣市|主計總處||
|12|公幼生佔比|教育部統計處|縣市|教育部|計算方式: 縣市公幼生人數/縣市幼兒園學生總人數|
|13|托嬰比率|衛福部統計處|縣市|衛福部|計算方式: 縣市托嬰總人數/縣市0-2歲人口數|
|14|各年齡區間女性勞動參與率|中華民國統計資訊網|縣市|主計總處||

    

---

### 四、預測模型建構方法

預測模型採用極限梯度提升模型(eXtreme Gradient Boosting; XGBoost)，由於XGBoost模型需要調整超參數，讓模型預測能力能夠更好。此處我們採用交叉驗證(Cross Validation)方法挑選模型超參數，交叉驗證的折數設定為5，採隨機切分方式。我們主要挑選以下超參數組合，共計有64個組合：

| 參數中文名稱 | 參數英文名稱 | 參數選擇範圍 |
| -------- | -------- | -------- |
| 學習比率 | learning_rate | 0.01, 0.1 |
| 最大深度 | max_depth | 3, 4, 5, 6, 7, 8, 9, 10 |
| 特徵隨機抽取比率 | colsample_bytree | 0.7, 0.9 |
| 樣本隨機抽取比率 | subsample | 0.7, 0.9|

    

另外，由於我們的資料屬於不平衡資料(Imbalanced Data)，所以在XGBoost模型中，額外設定正樣本權重(scale_pos_weight)參數為0.2886(即訓練集預測分類為0的樣本數/分類為1的樣本數)，讓模型能夠預測更好。

經過交叉驗證後，我們以AUC最高的參數組合做為最適參數組合，挑選出的參數組合為：

| 參數中文名稱 | 參數英文名稱 | 參數選擇範圍 |
| -------- | -------- | -------- |
| 學習比率 | learning_rate | 0.1 |
| 最大深度 | max_depth | 10 |
| 特徵隨機抽取比率 | colsample_bytree | 0.9 |
| 樣本隨機抽取比率 | subsample | 0.7 |
| 最佳疊代數 | num_boost_round | 22 |

   

我們以上述超參數組合，透過XGBoost模型對全部訓練集的資料進行學習，得到最後的預測模型。



